{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing inputs\n",
    "The inputs generation uses three step:\n",
    "1. Pulling data\n",
    "2. Formatting data to TFRecord files\n",
    "3. Writting TFRecord files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "/home/pchuang/.local/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import sys, os, io, hashlib, json\n",
    "import scipy.io\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from object_detection.utils import dataset_util\n",
    "from object_detection.utils import label_map_util\n",
    "\n",
    "# This is needed to display the images.\n",
    "%matplotlib inline\n",
    "\n",
    "# This is needed since the notebook is stored in the object_detection folder.\n",
    "sys.path.append(\"../../\")\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from utils import dataset_util\n",
    "from utils import label_map_util\n",
    "from utils import visualization_utils as vis_util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables\n",
    "\n",
    "We know the only label will be \"hand\", so the label map file is ready-to-use in the repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = './dataset/DeepQ'\n",
    "\n",
    "# Test dataset\n",
    "TEST_OUTPUT_FILENAME = './data/hands_test.record'\n",
    "\n",
    "# Training dataset\n",
    "TRAIN_OUTPUT_FILENAME = './data/hands_train.record'\n",
    "\n",
    "# Validation dataset\n",
    "VAL_OUTPUT_FILENAME = './data/hands_val.record'\n",
    "\n",
    "# The label map file with the \"hand\" label\n",
    "LABEL_MAP_PATH = './hands_label_map.pbtxt'\n",
    "label_map_dict = label_map_util.get_label_map_dict(LABEL_MAP_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tf_example(name, img_dir, ann_dir):\n",
    "\n",
    "    IMG_FILENAME = '%s.png' % name\n",
    "    ANN_FILENAME = 'label%s.json' % name[3:]\n",
    "    IMG_FULL_PATH = os.path.join(img_dir, IMG_FILENAME)\n",
    "    ANN_FULL_PATH = os.path.join(ann_dir, ANN_FILENAME)\n",
    "\n",
    "    with tf.gfile.GFile(IMG_FULL_PATH, 'rb') as fid:\n",
    "        encoded_jpg = fid.read()\n",
    "    encoded_jpg_io = io.BytesIO(encoded_jpg)\n",
    "    image = Image.open(encoded_jpg_io)\n",
    "    if image.format != 'PNG':\n",
    "        raise ValueError('Image format not PNG')\n",
    "    key = hashlib.sha256(encoded_jpg).hexdigest()\n",
    "\n",
    "    width, height = image.size\n",
    "\n",
    "    xmin = []\n",
    "    ymin = []\n",
    "    xmax = []\n",
    "    ymax = []\n",
    "    classes = []\n",
    "    classes_text = []\n",
    "    truncated = []\n",
    "    poses = []\n",
    "    difficult_obj = []\n",
    "\n",
    "    js = json.load(open(ANN_FULL_PATH, 'r'))\n",
    "    for label in js['bbox'].keys():\n",
    "        text_label = label + 'hand'\n",
    "        x_0, y_0, x_1, y_1 = js['bbox'][label]\n",
    "        x_0, x_1 = max(x_0, 0), max(x_1, 0)\n",
    "        y_0, y_1 = max(y_0, 0), max(y_1, 0)\n",
    "        x_0, x_1 = min(x_0, width), min(x_1, width)\n",
    "        y_0, y_1 = min(y_0, height), min(y_1, height)\n",
    "        \n",
    "        if x_1 > x_0 and y_1 > y_0:\n",
    "            # print(x_0, x_1, y_0, y_1, text_label)\n",
    "            # print(x_0, x_1, y_0, y_1, width, height, IMG_FILENAME)\n",
    "            xmin.append(float(x_0) / width)\n",
    "            ymin.append(float(y_0) / height)\n",
    "            xmax.append(float(x_1) / width)\n",
    "            ymax.append(float(y_1) / height)\n",
    "            classes_text.append(text_label.encode('utf-8'))\n",
    "            classes.append(label_map_dict[text_label])\n",
    "            truncated.append(0)\n",
    "            poses.append('Frontal'.encode('utf-8'))\n",
    "            difficult_obj.append(0)\n",
    "            \n",
    "            # print(xmin[-1], xmax[-1], ymin[-1], ymax[-1], width, height, IMG_FILENAME)\n",
    "            # plt.imshow(image)\n",
    "            # plt.show()\n",
    "            # vis_util.draw_bounding_box_on_image(image, ymin[-1], xmin[-1], ymax[-1], xmax[-1])\n",
    "            # plt.imshow(image)\n",
    "            # plt.show()\n",
    "        \n",
    "    return tf.train.Example(features=tf.train.Features(feature={\n",
    "        'image/height': dataset_util.int64_feature(height),\n",
    "        'image/width': dataset_util.int64_feature(width),\n",
    "        'image/filename': dataset_util.bytes_feature(\n",
    "              IMG_FILENAME.encode('utf-8')),\n",
    "        'image/source_id': dataset_util.bytes_feature(\n",
    "              IMG_FILENAME.encode('utf-8')),\n",
    "        'image/key/sha256': dataset_util.bytes_feature(key.encode('utf-8')),\n",
    "        'image/encoded': dataset_util.bytes_feature(encoded_jpg),\n",
    "        'image/format': dataset_util.bytes_feature('png'.encode('utf-8')),\n",
    "        'image/object/bbox/xmin': dataset_util.float_list_feature(xmin),\n",
    "        'image/object/bbox/xmax': dataset_util.float_list_feature(xmax),\n",
    "        'image/object/bbox/ymin': dataset_util.float_list_feature(ymin),\n",
    "        'image/object/bbox/ymax': dataset_util.float_list_feature(ymax),\n",
    "        'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
    "        'image/object/class/label': dataset_util.int64_list_feature(classes),\n",
    "        'image/object/difficult': dataset_util.int64_list_feature(difficult_obj),\n",
    "        'image/object/truncated': dataset_util.int64_list_feature(truncated),\n",
    "        'image/object/view': dataset_util.bytes_list_feature(poses),\n",
    "      }))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writting TFRecord files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tf_record(data_path, output_filename):\n",
    "    writer = tf.python_io.TFRecordWriter(output_filename)\n",
    "    print('Generating %s file...' % output_filename)\n",
    "    if 'val' in output_filename:\n",
    "        conditions = ['air', 'book']\n",
    "    elif 'test' in output_filename:\n",
    "        conditions = ['s009']                 \n",
    "    else:\n",
    "        conditions = ['s00{}'.format(i) for i in range(1, 9)]\n",
    "    \n",
    "    for cur_path in os.listdir(data_path):\n",
    "        if 'DeepQ' in cur_path:\n",
    "            data_dir = os.path.join(data_path, cur_path, 'data')\n",
    "            #print('\\t{}'.format(data_dir))\n",
    "            for sub_dir in os.listdir(data_dir):\n",
    "                if any([True if cond in sub_dir else False for cond in conditions]):\n",
    "                    print('\\tCollecting images in : ', os.path.join(data_dir, sub_dir))\n",
    "                    img_dir = os.path.join(data_dir, sub_dir, 'img')\n",
    "                    ann_dir = os.path.join(data_dir, sub_dir, 'label')\n",
    "                    for f in os.listdir(img_dir):\n",
    "                        if '.png' in f:\n",
    "                            img_name = f.split('.')[0]\n",
    "                            tf_example = create_tf_example(img_name, img_dir, ann_dir)\n",
    "                            writer.write(tf_example.SerializeToString())\n",
    "    writer.close()\n",
    "    print('%s written.' % output_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating ./data/hands_train.record file...\n",
      "./dataset/DeepQ/DeepQ-Synth-Hand-01/data\n",
      "\tCollecting images in :  ./dataset/DeepQ/DeepQ-Synth-Hand-01/data/s002\n",
      "\tCollecting images in :  ./dataset/DeepQ/DeepQ-Synth-Hand-01/data/s004\n",
      "\tCollecting images in :  ./dataset/DeepQ/DeepQ-Synth-Hand-01/data/s003\n",
      "\tCollecting images in :  ./dataset/DeepQ/DeepQ-Synth-Hand-01/data/s001\n",
      "./dataset/DeepQ/DeepQ-Synth-Hand-02/data\n",
      "\tCollecting images in :  ./dataset/DeepQ/DeepQ-Synth-Hand-02/data/s008\n"
     ]
    }
   ],
   "source": [
    "create_tf_record(DATA_PATH, TRAIN_OUTPUT_FILENAME)\n",
    "create_tf_record(DATA_PATH, VAL_OUTPUT_FILENAME)\n",
    "create_tf_record(DATA_PATH, TEST_OUTPUT_FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
