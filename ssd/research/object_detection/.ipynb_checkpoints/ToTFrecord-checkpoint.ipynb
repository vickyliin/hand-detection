{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing inputs\n",
    "The inputs generation uses three step:\n",
    "1. Pulling data\n",
    "2. Formatting data to TFRecord files\n",
    "3. Writting TFRecord files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import six.moves.urllib as urllib\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "\n",
    "from collections import defaultdict\n",
    "from io import StringIO\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "import scipy.io\n",
    "\n",
    "import wget\n",
    "import tarfile\n",
    "import io\n",
    "import hashlib\n",
    "\n",
    "# This is needed to display the images.\n",
    "%matplotlib inline\n",
    "\n",
    "# This is needed since the notebook is stored in the object_detection folder.\n",
    "sys.path.append(\"./models/\")\n",
    "sys.path.append(\"./models/object_detection\")\n",
    "\n",
    "from utils import dataset_util\n",
    "from utils import label_map_util\n",
    "from utils import visualization_utils as vis_util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables\n",
    "\n",
    "We know the only label will be \"hand\", so the label map file is ready-to-use in the repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = './dataset'\n",
    "\n",
    "# Test dataset\n",
    "TEST_IMG_DIR = os.path.join(DATA_PATH, 'test_dataset', 'test_data', 'images')\n",
    "TEST_ANN_DIR = os.path.join(DATA_PATH, 'test_dataset', 'test_data', 'annotations')\n",
    "TEST_OUTPUT_FILENAME = 'hands_test.record'\n",
    "\n",
    "# Training dataset\n",
    "TRAIN_IMG_DIR = os.path.join(DATA_PATH, 'training_dataset', 'training_data', 'images')\n",
    "TRAIN_ANN_DIR = os.path.join(DATA_PATH, 'training_dataset', 'training_data', 'annotations')\n",
    "TRAIN_OUTPUT_FILENAME = 'hands_train.record'\n",
    "\n",
    "# Validation dataset\n",
    "VAL_IMG_DIR = os.path.join(DATA_PATH, 'validation_dataset', 'validation_data', 'images')\n",
    "VAL_ANN_DIR = os.path.join(DATA_PATH, 'validation_dataset', 'validation_data', 'annotations')\n",
    "VAL_OUTPUT_FILENAME = 'hands_val.record'\n",
    "\n",
    "# The label map file with the \"hand\" label\n",
    "LABEL_MAP_PATH = 'hands_label_map.pbtxt'\n",
    "label_map_dict = label_map_util.get_label_map_dict(LABEL_MAP_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, io, hashlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "/home/pchuang/.local/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import dataset_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = './dataset'\n",
    "\n",
    "# Training dataset\n",
    "TRAIN_IMG_DIR = os.path.join(DATA_PATH, 'training_dataset', 'training_data', 'images')\n",
    "TRAIN_ANN_DIR = os.path.join(DATA_PATH, 'training_dataset', 'training_data', 'annotations')\n",
    "TRAIN_OUTPUT_FILENAME = 'hands_train.record'\n",
    "\n",
    "# The label map file with the \"hand\" label\n",
    "LABEL_MAP_PATH = 'hands_label_map.pbtxt'\n",
    "label_map_dict = {'hand':1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pulling data from University of Oxford \"Hands Dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading test_dataset.tar.gz...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'wget' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-6006869d544e>\u001b[0m in \u001b[0;36mpull_data\u001b[0;34m(data_filenames)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Downloading %s.tar.gz...'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdata_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mdata_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'http://www.robots.ox.ac.uk/~vgg/data/hands/downloads/%s.tar.gz'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdata_filename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mdata_filename_ext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Extracting %s...'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdata_filename_ext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'wget' is not defined"
     ]
    }
   ],
   "source": [
    "def pull_data(data_filenames):\n",
    "    # Load train, test and validation data\n",
    "    for data_filename in data_filenames:\n",
    "\n",
    "        print('Downloading %s.tar.gz...' % data_filename)\n",
    "        data_url = 'http://www.robots.ox.ac.uk/~vgg/data/hands/downloads/%s.tar.gz' % data_filename\n",
    "        data_filename_ext = wget.download(data_url)\n",
    "\n",
    "        print('Extracting %s...' % data_filename_ext)\n",
    "        data_tar = tarfile.open('%s' % data_filename_ext)\n",
    "        data_tar.extractall(path='dataset/')\n",
    "        data_tar.close()\n",
    "        \n",
    "%time pull_data(['test_dataset', 'validation_dataset', 'training_dataset'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAT file parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coords_from_mat(mat_filepath):\n",
    "    mat = scipy.io.loadmat(mat_filepath)\n",
    "    coords = []\n",
    "    i = 0\n",
    "    for e in mat['boxes'][0]:\n",
    "        coords.append(list())\n",
    "        c = 0\n",
    "        for d in e[0][0]:\n",
    "            if c > 3:\n",
    "                break\n",
    "            coords[i].append((d[0][0], d[0][1]))\n",
    "            c += 1\n",
    "        i += 1\n",
    "    return coords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formatting MAT files to TFRecord files\n",
    "Create a TF Example from training data name. Ex: if 'name' is 'Buffy_01', it will use Buffy_01.jpg file in IMG_PATH directory and Buffy_01.mat in ANN_PATH directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tf_example(name, img_dir, ann_dir):\n",
    "\n",
    "    IMG_FILENAME = '%s.jpg' % name\n",
    "    ANN_FILENAME = '%s.mat' % name\n",
    "    IMG_FULL_PATH = os.path.join(img_dir, IMG_FILENAME)\n",
    "    ANN_FULL_PATH = os.path.join(ann_dir, ANN_FILENAME)\n",
    "\n",
    "    with tf.gfile.GFile(IMG_FULL_PATH, 'rb') as fid:\n",
    "        encoded_jpg = fid.read()\n",
    "    encoded_jpg_io = io.BytesIO(encoded_jpg)\n",
    "    image = Image.open(encoded_jpg_io)\n",
    "    if image.format != 'JPEG':\n",
    "        raise ValueError('Image format not JPEG')\n",
    "    key = hashlib.sha256(encoded_jpg).hexdigest()\n",
    "\n",
    "    label = 'hand'\n",
    "    width, height = image.size\n",
    "\n",
    "    xmin = []\n",
    "    ymin = []\n",
    "    xmax = []\n",
    "    ymax = []\n",
    "    classes = []\n",
    "    classes_text = []\n",
    "    truncated = []\n",
    "    poses = []\n",
    "    difficult_obj = []\n",
    "\n",
    "    coords = coords_from_mat(ANN_FULL_PATH)\n",
    "\n",
    "    for coord in coords:\n",
    "\n",
    "        x_max, x_min, y_max, y_min = 0, float('inf'), 0, float('inf')\n",
    "        for y,x in coord:\n",
    "            x_max, x_min = max(x, x_max), min(x, x_min)\n",
    "            y_max, y_min = max(y, y_max), min(y, y_min) \n",
    "\n",
    "        xmin.append(max(float(x_min) / width, 0.0))\n",
    "        ymin.append(max(float(y_min) / height, 0.0))\n",
    "        xmax.append(min(float(x_max) / width, 1.0))\n",
    "        ymax.append(min(float(y_max) / height, 1.0))\n",
    "        classes_text.append(label.encode('utf8'))\n",
    "        classes.append(label_map_dict[label])\n",
    "        truncated.append(0)\n",
    "        poses.append('Frontal'.encode('utf8'))\n",
    "        difficult_obj.append(0)\n",
    "\n",
    "    return tf.train.Example(features=tf.train.Features(feature={\n",
    "        'image/height': dataset_util.int64_feature(height),\n",
    "        'image/width': dataset_util.int64_feature(width),\n",
    "        'image/filename': dataset_util.bytes_feature(\n",
    "              IMG_FILENAME.encode('utf8')),\n",
    "        'image/source_id': dataset_util.bytes_feature(\n",
    "              IMG_FILENAME.encode('utf8').encode('utf8')),\n",
    "        'image/key/sha256': dataset_util.bytes_feature(key),\n",
    "        'image/encoded': dataset_util.bytes_feature(encoded_jpg),\n",
    "        'image/format': dataset_util.bytes_feature('jpeg'.encode('utf8')),\n",
    "        'image/object/bbox/xmin': dataset_util.float_list_feature(xmin),\n",
    "        'image/object/bbox/xmax': dataset_util.float_list_feature(xmax),\n",
    "        'image/object/bbox/ymin': dataset_util.float_list_feature(ymin),\n",
    "        'image/object/bbox/ymax': dataset_util.float_list_feature(ymax),\n",
    "        'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
    "        'image/object/class/label': dataset_util.int64_list_feature(classes),\n",
    "        'image/object/difficult': dataset_util.int64_list_feature(difficult_obj),\n",
    "        'image/object/truncated': dataset_util.int64_list_feature(truncated),\n",
    "        'image/object/view': dataset_util.bytes_list_feature(poses),\n",
    "      }))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writting TFRecord files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tf_record(img_dir, ann_dir, output_filename):\n",
    "    writer = tf.python_io.TFRecordWriter(output_filename)\n",
    "    print('Generating %s file...' % output_filename)\n",
    "    for f in os.listdir(img_dir):\n",
    "        if '.jpg' in f:\n",
    "            img_name = f.split('.')[0]\n",
    "            tf_example = create_tf_example(img_name, img_dir, ann_dir)\n",
    "            writer.write(tf_example.SerializeToString())\n",
    "    writer.close()\n",
    "    print('%s written.' % output_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating hands_train.record file...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'bytes' object has no attribute 'encode'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-dcea6ec1b9f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcreate_tf_record\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTRAIN_IMG_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTRAIN_ANN_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTRAIN_OUTPUT_FILENAME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-a0482c6af118>\u001b[0m in \u001b[0;36mcreate_tf_record\u001b[0;34m(img_dir, ann_dir, output_filename)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'.jpg'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0mimg_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m             \u001b[0mtf_example\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_tf_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mann_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m             \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf_example\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerializeToString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-ded3f9e8cede>\u001b[0m in \u001b[0;36mcreate_tf_example\u001b[0;34m(name, img_dir, ann_dir)\u001b[0m\n\u001b[1;32m     52\u001b[0m               IMG_FILENAME.encode('utf8')),\n\u001b[1;32m     53\u001b[0m         'image/source_id': dataset_util.bytes_feature(\n\u001b[0;32m---> 54\u001b[0;31m               IMG_FILENAME.encode('utf8').encode('utf8')),\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0;34m'image/key/sha256'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdataset_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbytes_feature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;34m'image/encoded'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdataset_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbytes_feature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_jpg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'bytes' object has no attribute 'encode'"
     ]
    }
   ],
   "source": [
    "create_tf_record(TRAIN_IMG_DIR, TRAIN_ANN_DIR, TRAIN_OUTPUT_FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_tf_record(TRAIN_IMG_DIR, TRAIN_ANN_DIR, TRAIN_OUTPUT_FILENAME)\n",
    "create_tf_record(VAL_IMG_DIR, VAL_ANN_DIR, VAL_OUTPUT_FILENAME)\n",
    "create_tf_record(TEST_IMG_DIR, TEST_ANN_DIR, TEST_OUTPUT_FILENAME)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
